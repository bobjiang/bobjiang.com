<!DOCTYPE html>
<html lang="zh-cn">
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>土法炮制：RNN 层是如何实现的？ - DTeam 团队日志</title>
	<meta name="description" content="本文将展示一个简单的 RNN 构建过程。为了测试自行实现的效果，我们将采用 IMDB 评论数据集作为验证。" />
	<meta name="author" content="胡键" />
	<link rel="icon" type="image/png" href=/images/favicon.png /><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta property="og:title" content="土法炮制：RNN 层是如何实现的？" />
<meta property="og:description" content="本文将展示一个简单的 RNN 构建过程。为了测试自行实现的效果，我们将采用 IMDB 评论数据集作为验证。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://blog.dteam.top/posts/2020-02/implement-myrnn-with-tensorflow.html" />
<meta property="article:published_time" content="2020-02-13T11:21:35+08:00" />
<meta property="article:modified_time" content="2020-02-13T11:21:35+08:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="土法炮制：RNN 层是如何实现的？"/>
<meta name="twitter:description" content="本文将展示一个简单的 RNN 构建过程。为了测试自行实现的效果，我们将采用 IMDB 评论数据集作为验证。"/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:200,300"
		rel="stylesheet">

	<link rel="stylesheet" type="text/css" media="screen" href="https://blog.dteam.top/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://blog.dteam.top/css/main.css" /><link rel="stylesheet" type="text/css" href="https://blog.dteam.top/css/dark.css"
		media="(prefers-color-scheme: dark)"  />

	<script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
	<script src="https://blog.dteam.top/js/main.js"></script>
	
	<script type="application/ld+json">{
		  "@context": "http://schema.org",
		  "@type": "BlogPosting",
		  "headline": "土法炮制：RNN 层是如何实现的？",
		  "genre": "",
		  "datePublished": "2020-02-13T03:21:35Z",
		  "dateModified": "2020-02-13T03:21:35Z",
		  "description": "本文将展示一个简单的 RNN 构建过程。为了测试自行实现的效果，我们将采用 IMDB 评论数据集作为验证。",
		  "keywords" : [ "机器学习", "TensorFlow" ],
		  "author": {
		    "@type": "Person",
		    "name": "胡键"
		  },
		  "mainEntityOfPage": {
		    "@type": "WebPage",
		    "@id": "https://blog.dteam.top/"
		  },
		  "publisher": {
		    "@type": "Organization",
		    "name": "DTeam 团队日志",
		    "logo": {
		      "@type": "ImageObject",
		      "url": "https://blog.dteam.top/images/favicon.png"
		    }
		  }
		}</script>
</head>


<body>
	<div class="container wrapper post">
		<div class="header">
	<h1 class="site-title"><a href="https://blog.dteam.top/">DTeam 团队日志</a></h1>
	<div class="site-description"><h2>Doer、Delivery、Dream</h2><nav class="nav social">
			<ul class="flat"><a href="https://github.com/DTeam-Top" title="Github"><i data-feather="github"></i></a><a href="mailto:jian.hu@shifudao.com" title="Mail"><i data-feather="mail"></i></a><a href="/index.xml" title="RSS"><i data-feather="rss"></i></a></ul>
		</nav>
	</div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/">主页</a>
			</li>
			
			<li>
				<a href="/posts.html">所有文章</a>
			</li>
			
			<li>
				<a href="/tools.html">工具推荐</a>
			</li>
			
			<li>
				<a href="/about.html">关于我们</a>
			</li>
			
			<li>
				<a href="/tags.html">标签</a>
			</li>
			
                        <li>
                            <div class="statistics">
                                <span id="busuanzi_container_site_pv">总访问 <span id="busuanzi_value_site_pv"></span> </span>
                                <span id="busuanzi_container_site_uv">总人气 <span id="busuanzi_value_site_uv"></span> </span>
                            </div>
                        </li>
		</ul>
	</nav>
</div>


		<div class="post-header">
			<h1 class="title">土法炮制：RNN 层是如何实现的？</h1>
			<div class="meta">胡键 Posted at &mdash; Feb 13, 2020
				<span class="meta" id="busuanzi_container_page_pv">阅读 <span id="busuanzi_value_page_pv"></span></span>
			</div>
		</div>

		<div class="share-component" data-sites="qq,weibo,wechat,douban,twitter,facebook"
			data-description="Share.js - 一键分享到微博，QQ空间，腾讯微博，人人，豆瓣"></div>

		
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">
		<script src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>

		<div class="markdown">
			<p>讲过前馈网络和卷积网络之后，那么就让我们来看看循环网络的实现。</p>
<p>相比前面提到过的网络类型，循环网络存在“记忆”，即它内部会保留过去的状态，并作为下次处理的输入的一部分。因此，在循环网络中，节点的输出如下：</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">output_t = activation(dot(W, input_t) + dot(U, state_t) + b)
</code></pre></div><p>其中，state_t = output_t，上一次的计算结果。将 RNN 概念图展开，得出下图（摘自《Deep.Learning.with.Python》）：</p>
<p><img src="imgs/rnn-unfold.png" alt="rnn-unfold"></p>
<p>本文同样以 imdb 评论为例来进行说明。</p>
<h2 id="-keras-">使用 Keras 的做法</h2>
<p>Keras 中提供了 RNN 的简单实现： SimpleRNN ，先看看如何用它来搭建模型。注意，这里面需要用到 Embedding 层。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#000;font-weight:bold">import</span> <span style="color:#555">tensorflow</span> <span style="color:#000;font-weight:bold">as</span> <span style="color:#555">tf</span>
<span style="color:#000;font-weight:bold">from</span> <span style="color:#555">tensorflow.keras.datasets</span> <span style="color:#000;font-weight:bold">import</span> imdb
<span style="color:#000;font-weight:bold">from</span> <span style="color:#555">tensorflow.keras</span> <span style="color:#000;font-weight:bold">import</span> preprocessing

max_features <span style="color:#000;font-weight:bold">=</span> <span style="color:#099">10000</span>
maxlen <span style="color:#000;font-weight:bold">=</span> <span style="color:#099">500</span>

<span style="color:#998;font-style:italic"># 加载数据</span>
(x_train, y_train), (x_test, y_test) <span style="color:#000;font-weight:bold">=</span> imdb<span style="color:#000;font-weight:bold">.</span>load_data(num_words<span style="color:#000;font-weight:bold">=</span>max_features)

<span style="color:#998;font-style:italic"># 预处理数据，将数据分割成相等长度</span>
x_train <span style="color:#000;font-weight:bold">=</span> preprocessing<span style="color:#000;font-weight:bold">.</span>sequence<span style="color:#000;font-weight:bold">.</span>pad_sequences(x_train, maxlen<span style="color:#000;font-weight:bold">=</span>maxlen)
x_test <span style="color:#000;font-weight:bold">=</span> preprocessing<span style="color:#000;font-weight:bold">.</span>sequence<span style="color:#000;font-weight:bold">.</span>pad_sequences(x_test, maxlen<span style="color:#000;font-weight:bold">=</span>maxlen)

<span style="color:#998;font-style:italic"># 模型定义</span>
model <span style="color:#000;font-weight:bold">=</span> tf<span style="color:#000;font-weight:bold">.</span>keras<span style="color:#000;font-weight:bold">.</span>models<span style="color:#000;font-weight:bold">.</span>Sequential([
  tf<span style="color:#000;font-weight:bold">.</span>keras<span style="color:#000;font-weight:bold">.</span>layers<span style="color:#000;font-weight:bold">.</span>Embedding(max_features, <span style="color:#099">32</span>, input_length<span style="color:#000;font-weight:bold">=</span>maxlen),
  tf<span style="color:#000;font-weight:bold">.</span>keras<span style="color:#000;font-weight:bold">.</span>layers<span style="color:#000;font-weight:bold">.</span>SimpleRNN(<span style="color:#099">32</span>, return_sequences<span style="color:#000;font-weight:bold">=</span><span style="color:#999">True</span>),
  tf<span style="color:#000;font-weight:bold">.</span>keras<span style="color:#000;font-weight:bold">.</span>layers<span style="color:#000;font-weight:bold">.</span>SimpleRNN(<span style="color:#099">32</span>),
  tf<span style="color:#000;font-weight:bold">.</span>keras<span style="color:#000;font-weight:bold">.</span>layers<span style="color:#000;font-weight:bold">.</span>Dense(<span style="color:#099">1</span>, activation<span style="color:#000;font-weight:bold">=</span><span style="color:#d14"></span><span style="color:#d14">&#39;</span><span style="color:#d14">sigmoid</span><span style="color:#d14">&#39;</span>)
])

model<span style="color:#000;font-weight:bold">.</span>compile(optimizer<span style="color:#000;font-weight:bold">=</span><span style="color:#d14"></span><span style="color:#d14">&#39;</span><span style="color:#d14">rmsprop</span><span style="color:#d14">&#39;</span>,
              loss<span style="color:#000;font-weight:bold">=</span><span style="color:#d14"></span><span style="color:#d14">&#39;</span><span style="color:#d14">binary_crossentropy</span><span style="color:#d14">&#39;</span>,
              metrics<span style="color:#000;font-weight:bold">=</span>[<span style="color:#d14"></span><span style="color:#d14">&#39;</span><span style="color:#d14">accuracy</span><span style="color:#d14">&#39;</span>])

<span style="color:#998;font-style:italic"># 训练</span>
model<span style="color:#000;font-weight:bold">.</span>fit(x_train, y_train, epochs<span style="color:#000;font-weight:bold">=</span><span style="color:#099">10</span>, batch_size<span style="color:#000;font-weight:bold">=</span><span style="color:#099">128</span>, validation_split<span style="color:#000;font-weight:bold">=</span><span style="color:#099">0.2</span>)

<span style="color:#998;font-style:italic"># 预测</span>
<span style="color:#000;font-weight:bold">print</span>(y_train[:<span style="color:#099">3</span>])
<span style="color:#000;font-weight:bold">print</span>(model<span style="color:#000;font-weight:bold">.</span>predict_classes(x_test[:<span style="color:#099">3</span>])<span style="color:#000;font-weight:bold">.</span>flatten())
</code></pre></div><p>对于 SimpleRNN，其输出可以有两种格式，由 return_sequences 控制：</p>
<ul>
<li>= True，返回 (batch_size, time_steps, output_features)，即每一次的输出结果都会保存，当 SimpleRNN 后跟 SimpleRNN 时使用。</li>
<li>= False，返回 (batch_size, output_features)，即最后一次的输出，当 SimpleRNN 为最后一个 RNN 层时使用。</li>
</ul>
<h2 id="-tf-">使用 TF 实现自定义结构</h2>
<p>相比起 TF 的正统实现（layer + cell），本文做了相当的简化：只构建 SimpleRNN 层，主要的代码参考了《Deep.Learning.with.Python》。</p>
<p>同样，为了保证每篇的独立性，所有对象的代码都贴出来了，如果不想看之前重复的代码可以直接去看 MySimpleRNN</p>
<h3 id="mydense">MyDense</h3>
<p>同前。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#000;font-weight:bold">class</span> <span style="color:#458;font-weight:bold">MyDense</span>(Layer):

    <span style="color:#000;font-weight:bold">def</span> __init__(<span style="color:#999">self</span>, units<span style="color:#000;font-weight:bold">=</span><span style="color:#099">32</span>):
        <span style="color:#0086b3">super</span>(MyDense, <span style="color:#999">self</span>)<span style="color:#000;font-weight:bold">.</span>__init__()
        <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>units <span style="color:#000;font-weight:bold">=</span> units

    <span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">build</span>(<span style="color:#999">self</span>, input_shape):
        <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>w <span style="color:#000;font-weight:bold">=</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>add_weight(shape<span style="color:#000;font-weight:bold">=</span>(input_shape[<span style="color:#000;font-weight:bold">-</span><span style="color:#099">1</span>], <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>units),
            initializer<span style="color:#000;font-weight:bold">=</span><span style="color:#d14"></span><span style="color:#d14">&#39;</span><span style="color:#d14">random_normal</span><span style="color:#d14">&#39;</span>, trainable<span style="color:#000;font-weight:bold">=</span><span style="color:#999">True</span>)
        <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>b <span style="color:#000;font-weight:bold">=</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>add_weight(shape<span style="color:#000;font-weight:bold">=</span>(<span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>units,),
            initializer<span style="color:#000;font-weight:bold">=</span><span style="color:#d14"></span><span style="color:#d14">&#39;</span><span style="color:#d14">random_normal</span><span style="color:#d14">&#39;</span>, trainable<span style="color:#000;font-weight:bold">=</span><span style="color:#999">True</span>)

    <span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">call</span>(<span style="color:#999">self</span>, inputs):
        <span style="color:#000;font-weight:bold">return</span> tf<span style="color:#000;font-weight:bold">.</span>nn<span style="color:#000;font-weight:bold">.</span>sigmoid(tf<span style="color:#000;font-weight:bold">.</span>matmul(inputs, <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>w) <span style="color:#000;font-weight:bold">+</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>b)
</code></pre></div><h3 id="myembedding">MyEmbedding</h3>
<p>同前。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#000;font-weight:bold">class</span> <span style="color:#458;font-weight:bold">MyEmbedding</span>(Layer):
    
    <span style="color:#000;font-weight:bold">def</span> __init__(<span style="color:#999">self</span>, input_unit, output_unit):
        <span style="color:#0086b3">super</span>(MyEmbedding, <span style="color:#999">self</span>)<span style="color:#000;font-weight:bold">.</span>__init__()
        <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>input_unit <span style="color:#000;font-weight:bold">=</span> input_unit
        <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>output_unit <span style="color:#000;font-weight:bold">=</span> output_unit

    <span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">build</span>(<span style="color:#999">self</span>, input_shape):
        <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>embedding <span style="color:#000;font-weight:bold">=</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>add_weight(shape<span style="color:#000;font-weight:bold">=</span>(<span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>input_unit, <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>output_unit),
            initializer<span style="color:#000;font-weight:bold">=</span><span style="color:#d14"></span><span style="color:#d14">&#39;</span><span style="color:#d14">random_normal</span><span style="color:#d14">&#39;</span>, trainable<span style="color:#000;font-weight:bold">=</span><span style="color:#999">True</span>)

    <span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">call</span>(<span style="color:#999">self</span>, inputs):
        <span style="color:#000;font-weight:bold">return</span> tf<span style="color:#000;font-weight:bold">.</span>nn<span style="color:#000;font-weight:bold">.</span>embedding_lookup(<span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>embedding, inputs)
</code></pre></div><h3 id="mysimplernn">MySimpleRNN</h3>
<p>自定义 SimpleRNN 层，注意：</p>
<ul>
<li>继承 Layer 的规范，实现 build 和 call 。</li>
<li>build 负责初始化状态矩阵、权重和偏置，来自 Layer 。注意它们的 shape：
<ul>
<li>权重：输入 x 输出</li>
<li>偏置：无</li>
<li>状态矩阵：输出 x 输出</li>
</ul>
</li>
<li>call 负责计算（内建循环，循环次数即时间步骤，来自第二维长度），来自 Layer 。</li>
</ul>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#000;font-weight:bold">class</span> <span style="color:#458;font-weight:bold">MySimpleRNN</span>(Layer):
    
    <span style="color:#000;font-weight:bold">def</span> __init__(<span style="color:#999">self</span>, unit, return_sequences<span style="color:#000;font-weight:bold">=</span><span style="color:#999">False</span>):
        <span style="color:#0086b3">super</span>(MySimpleRNN, <span style="color:#999">self</span>)<span style="color:#000;font-weight:bold">.</span>__init__()
        <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>units <span style="color:#000;font-weight:bold">=</span> unit
        <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>return_sequences <span style="color:#000;font-weight:bold">=</span> return_sequences

    <span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">build</span>(<span style="color:#999">self</span>, input_shape):
        <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>w <span style="color:#000;font-weight:bold">=</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>add_weight(shape<span style="color:#000;font-weight:bold">=</span>(input_shape[<span style="color:#000;font-weight:bold">-</span><span style="color:#099">1</span>], <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>units),
            initializer<span style="color:#000;font-weight:bold">=</span><span style="color:#d14"></span><span style="color:#d14">&#39;</span><span style="color:#d14">random_normal</span><span style="color:#d14">&#39;</span>, trainable<span style="color:#000;font-weight:bold">=</span><span style="color:#999">True</span>)
        <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>b <span style="color:#000;font-weight:bold">=</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>add_weight(shape<span style="color:#000;font-weight:bold">=</span>(<span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>units,),
            initializer<span style="color:#000;font-weight:bold">=</span><span style="color:#d14"></span><span style="color:#d14">&#39;</span><span style="color:#d14">random_normal</span><span style="color:#d14">&#39;</span>, trainable<span style="color:#000;font-weight:bold">=</span><span style="color:#999">True</span>)
        <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>u <span style="color:#000;font-weight:bold">=</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>add_weight(shape<span style="color:#000;font-weight:bold">=</span>(<span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>units, <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>units),
            initializer<span style="color:#000;font-weight:bold">=</span><span style="color:#d14"></span><span style="color:#d14">&#39;</span><span style="color:#d14">random_normal</span><span style="color:#d14">&#39;</span>, trainable<span style="color:#000;font-weight:bold">=</span><span style="color:#999">True</span>)

    <span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">call</span>(<span style="color:#999">self</span>, inputs):
        state <span style="color:#000;font-weight:bold">=</span> tf<span style="color:#000;font-weight:bold">.</span>zeros((<span style="color:#099">1</span>, <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>units))
        outputs <span style="color:#000;font-weight:bold">=</span> []
        <span style="color:#000;font-weight:bold">for</span> step <span style="color:#000;font-weight:bold">in</span> <span style="color:#0086b3">range</span>(inputs<span style="color:#000;font-weight:bold">.</span>shape[<span style="color:#099">1</span>]):
            output <span style="color:#000;font-weight:bold">=</span> tf<span style="color:#000;font-weight:bold">.</span>nn<span style="color:#000;font-weight:bold">.</span>tanh(tf<span style="color:#000;font-weight:bold">.</span>matmul(inputs[:, step, :], <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>w) <span style="color:#000;font-weight:bold">+</span> tf<span style="color:#000;font-weight:bold">.</span>matmul(state, <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>u) <span style="color:#000;font-weight:bold">+</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>b)
            outputs<span style="color:#000;font-weight:bold">.</span>append([output])
            state <span style="color:#000;font-weight:bold">=</span> output
        <span style="color:#998;font-style:italic"># 注意 shape 的变化</span>
        <span style="color:#000;font-weight:bold">return</span> tf<span style="color:#000;font-weight:bold">.</span>transpose(tf<span style="color:#000;font-weight:bold">.</span>concat(outputs, <span style="color:#099">0</span>), (<span style="color:#099">1</span>, <span style="color:#099">0</span>, <span style="color:#099">2</span>)) <span style="color:#000;font-weight:bold">if</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>return_sequences <span style="color:#000;font-weight:bold">else</span> output
</code></pre></div><h3 id="mymodel">MyModel</h3>
<p>同前。</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#000;font-weight:bold">class</span> <span style="color:#458;font-weight:bold">MyModel</span>(Layer):

    <span style="color:#000;font-weight:bold">def</span> __init__(<span style="color:#999">self</span>, layers):
        <span style="color:#0086b3">super</span>(MyModel, <span style="color:#999">self</span>)<span style="color:#000;font-weight:bold">.</span>__init__()
        <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>layers <span style="color:#000;font-weight:bold">=</span> layers

    <span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">call</span>(<span style="color:#999">self</span>, inputs):
        x <span style="color:#000;font-weight:bold">=</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>layers[<span style="color:#099">0</span>](inputs)
        <span style="color:#000;font-weight:bold">for</span> layer <span style="color:#000;font-weight:bold">in</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>layers[<span style="color:#099">1</span>:<span style="color:#000;font-weight:bold">-</span><span style="color:#099">1</span>]:
            x <span style="color:#000;font-weight:bold">=</span> layer(x)
        result <span style="color:#000;font-weight:bold">=</span> <span style="color:#999">self</span><span style="color:#000;font-weight:bold">.</span>layers[<span style="color:#000;font-weight:bold">-</span><span style="color:#099">1</span>](x)
        <span style="color:#000;font-weight:bold">return</span> result
    
    <span style="color:#000;font-weight:bold">def</span> <span style="color:#900;font-weight:bold">train</span>(<span style="color:#999">self</span>, x_train, y_train, epochs <span style="color:#000;font-weight:bold">=</span> <span style="color:#099">5</span>):
        loss <span style="color:#000;font-weight:bold">=</span> tf<span style="color:#000;font-weight:bold">.</span>keras<span style="color:#000;font-weight:bold">.</span>losses<span style="color:#000;font-weight:bold">.</span>BinaryCrossentropy()
        optimizer <span style="color:#000;font-weight:bold">=</span> tf<span style="color:#000;font-weight:bold">.</span>keras<span style="color:#000;font-weight:bold">.</span>optimizers<span style="color:#000;font-weight:bold">.</span>RMSprop()
        accuracy <span style="color:#000;font-weight:bold">=</span> tf<span style="color:#000;font-weight:bold">.</span>keras<span style="color:#000;font-weight:bold">.</span>metrics<span style="color:#000;font-weight:bold">.</span>Accuracy()

        dataset <span style="color:#000;font-weight:bold">=</span> tf<span style="color:#000;font-weight:bold">.</span>data<span style="color:#000;font-weight:bold">.</span>Dataset<span style="color:#000;font-weight:bold">.</span>from_tensor_slices((x_train, y_train))
        dataset <span style="color:#000;font-weight:bold">=</span> dataset<span style="color:#000;font-weight:bold">.</span>shuffle(buffer_size<span style="color:#000;font-weight:bold">=</span><span style="color:#099">1024</span>)<span style="color:#000;font-weight:bold">.</span>batch(<span style="color:#099">64</span>)

        <span style="color:#000;font-weight:bold">for</span> epoch <span style="color:#000;font-weight:bold">in</span> <span style="color:#0086b3">range</span>(epochs):
            <span style="color:#000;font-weight:bold">for</span> step, (x, y) <span style="color:#000;font-weight:bold">in</span> <span style="color:#0086b3">enumerate</span>(dataset):
                <span style="color:#000;font-weight:bold">with</span> tf<span style="color:#000;font-weight:bold">.</span>GradientTape() <span style="color:#000;font-weight:bold">as</span> tape:

                    <span style="color:#998;font-style:italic"># Forward pass.</span>
                    y_pred <span style="color:#000;font-weight:bold">=</span> model(x)
                    
                    <span style="color:#998;font-style:italic"># Loss value for this batch.</span>
                    loss_value <span style="color:#000;font-weight:bold">=</span> loss(y, y_pred)

                    <span style="color:#998;font-style:italic"># Get gradients of loss wrt the weights.</span>
                    gradients <span style="color:#000;font-weight:bold">=</span> tape<span style="color:#000;font-weight:bold">.</span>gradient(loss_value, model<span style="color:#000;font-weight:bold">.</span>trainable_weights)

                    <span style="color:#998;font-style:italic"># Update the weights of our linear layer.</span>
                    optimizer<span style="color:#000;font-weight:bold">.</span>apply_gradients(<span style="color:#0086b3">zip</span>(gradients, model<span style="color:#000;font-weight:bold">.</span>trainable_weights))
                    
                    <span style="color:#998;font-style:italic"># Update the running accuracy.</span>
                    accuracy<span style="color:#000;font-weight:bold">.</span>update_state(y, tf<span style="color:#000;font-weight:bold">.</span>cast(y_pred <span style="color:#000;font-weight:bold">&gt;</span><span style="color:#000;font-weight:bold">=</span> <span style="color:#099">0.5</span>, dtype<span style="color:#000;font-weight:bold">=</span>tf<span style="color:#000;font-weight:bold">.</span>int64))

                <span style="color:#000;font-weight:bold">print</span>(<span style="color:#d14"></span><span style="color:#d14">&#39;</span><span style="color:#d14">Epoch:</span><span style="color:#d14">&#39;</span>, epoch, <span style="color:#d14"></span><span style="color:#d14">&#39;</span><span style="color:#d14">, Loss from last epoch: </span><span style="color:#d14">%.3f</span><span style="color:#d14">&#39;</span> <span style="color:#000;font-weight:bold">%</span> loss_value, <span style="color:#d14"></span><span style="color:#d14">&#39;</span><span style="color:#d14">, Total running accuracy so far: </span><span style="color:#d14">%.3f</span><span style="color:#d14">&#39;</span> <span style="color:#000;font-weight:bold">%</span> accuracy<span style="color:#000;font-weight:bold">.</span>result(), end<span style="color:#000;font-weight:bold">=</span><span style="color:#d14"></span><span style="color:#d14">&#39;</span><span style="color:#d14">\r</span><span style="color:#d14">&#39;</span>)
            <span style="color:#000;font-weight:bold">print</span>(<span style="color:#d14"></span><span style="color:#d14">&#39;</span><span style="color:#d14">\n</span><span style="color:#d14">&#39;</span>)
</code></pre></div><p>看看效果吧：</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#998;font-style:italic"># 定义</span>
model <span style="color:#000;font-weight:bold">=</span> MyModel([
    MyEmbedding(max_features, <span style="color:#099">32</span>),
    MySimpleRNN(<span style="color:#099">32</span>, <span style="color:#999">True</span>),
    MySimpleRNN(<span style="color:#099">32</span>),
    MyDense(<span style="color:#099">1</span>)
])

<span style="color:#998;font-style:italic"># 训练</span>
model<span style="color:#000;font-weight:bold">.</span>train(x_train, y_train, <span style="color:#099">10</span>)

<span style="color:#998;font-style:italic"># 预测</span>
<span style="color:#000;font-weight:bold">print</span>(y_train[:<span style="color:#099">20</span>])
<span style="color:#000;font-weight:bold">print</span>(tf<span style="color:#000;font-weight:bold">.</span>cast(model(x_test[:<span style="color:#099">20</span>]) <span style="color:#000;font-weight:bold">&gt;</span><span style="color:#000;font-weight:bold">=</span> <span style="color:#099">0.5</span>, dtype<span style="color:#000;font-weight:bold">=</span>tf<span style="color:#000;font-weight:bold">.</span>int64)<span style="color:#000;font-weight:bold">.</span>numpy()<span style="color:#000;font-weight:bold">.</span>flatten())
</code></pre></div><p>关于代码注意几点：</p>
<ul>
<li>MySimpleRNN 中输出的 shape 的变化，参考上面的定义。</li>
<li>timestep 长度即为 Sequence 大小</li>
<li>尽量使用 tf 的操作来进行 shape 变化，否则容易出现“梯度不存在”的错误，参考错误信息如下：</li>
</ul>
<blockquote>
<p>Gradients does not exist for variables &hellip;</p>
</blockquote>

		</div>

		<div class="post-tags">
			
			
			<nav class="nav tags">
				<ul class="flat">
					
					<li><a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html">机器学习</a></li>
					
					<li><a href="/tags/tensorflow.html">TensorFlow</a></li>
					
				</ul>
			</nav>
			
			
		</div></div>
	<div class="footer wrapper">
    <p><img src="/images/mingpian.png"></p>
    <nav class="nav">
        <div><a href="http://www.beian.miit.gov.cn">陕ICP备18009003号-3</a> | 
            <a href="mailto:jian.hu@shifudao.com">联系我们</a> | <a href="https://github.com/vividvilla/ezhil">Ezhil theme</a> | Built with <a href="https://gohugo.io">Hugo</a>
        </div>
    </nav>
</div><script>feather.replace();
       (function () {
               if (window.location.href.endsWith('about.html') ||
                       window.location.href.endsWith('posts.html') ||
                       window.location.href.endsWith('localhost:1313/')) {
                       return false;
               };

               var httpRequest = new XMLHttpRequest();
               if (!httpRequest) {
                       alert('Giving up :( Cannot create an XMLHTTP instance');
                       return false;
               }

               httpRequest.onreadystatechange = alertContents;
               httpRequest.open('GET', 'https://recommend.blog.dteam.top/');
               httpRequest.send();

               function alertContents() {
                       if (httpRequest.readyState === XMLHttpRequest.DONE) {
                               if (httpRequest.status === 200) {
                                       var div = document.getElementsByTagName("div")[0];
                                       div.innerHTML += '<hr><h3 class="page-title">其他文章</h3>' + httpRequest.responseText.replace('posts',
                                               'post-header');
                               }
                       }
               }
       })();
</script><script>
    var _hmt = _hmt || [];
    (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?7ee18e8ed5acdd8c702a82c2d1aae74e";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>
<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

</body>

</html>